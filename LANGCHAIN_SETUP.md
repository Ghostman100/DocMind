# LangChain Integration - Quick Start Guide

## –û–±–∑–æ—Ä

DocMind —Ç–µ–ø–µ—Ä—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–≤–∞ —Å–ø–æ—Å–æ–±–∞ —Ä–∞–±–æ—Ç—ã —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏:

1. **–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞** (`/ingest`, `/query`) - –ë—ã—Å—Ç—Ä–∞—è –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
2. **LangChain —Å–∏—Å—Ç–µ–º–∞** (`/langchain/*`) - –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –≤–∫–ª—é—á–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—é –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –ø—É–Ω–∫—Ç–æ–≤

–û–±–∞ –ø–æ–¥—Ö–æ–¥–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º—ã –∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –æ–¥–Ω—É –∫–æ–ª–ª–µ–∫—Ü–∏—é Qdrant.

## –£—Å—Ç–∞–Ω–æ–≤–∫–∞

### 1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

```bash
pip install -r requirements.txt
```

–≠—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ LangChain –ø–∞–∫–µ—Ç—ã:
- `langchain==0.3.7`
- `langchain-qdrant==0.2.0`
- `langchain-community==0.3.5`
- `langchain-text-splitters==0.3.2`
- `langchain-openai==0.2.5`

### 2. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ .env —Ñ–∞–π–ª

–°–∫–æ–ø–∏—Ä—É–π—Ç–µ `.env.example`:
```bash
cp .env.example .env
```

**–î–ª—è –±–∞–∑–æ–≤–æ–≥–æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞** (ingest, query) –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ —Ç–æ–ª—å–∫–æ Qdrant:
```env
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=your-api-key-if-needed
```

**–î–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏** –¥–æ–±–∞–≤—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ LLM:
```env
LANGCHAIN_ENABLED=true
LLM_PROVIDER=openai
LLM_API_KEY=sk-your-openai-api-key
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.0
```

### 3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–µ—Ä–≤–µ—Ä

```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

API –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –¥–æ—Å—Ç—É–ø–Ω–∞ –Ω–∞ `http://localhost:8000/docs`

## –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –°—Ü–µ–Ω–∞—Ä–∏–π 1: –ë–∞–∑–æ–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–∏—Å–∫ (–±–µ–∑ LLM API –∫–ª—é—á–∞)

```python
import requests

BASE_URL = "http://localhost:8000"

# 1. –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç —á–µ—Ä–µ–∑ LangChain
response = requests.post(
    f"{BASE_URL}/langchain/ingest",
    json={
        "document_name": "–¢–µ–Ω–¥–µ—Ä ‚Ññ123",
        "text": "–î–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Ç–µ–Ω–¥–µ—Ä–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏..."
    }
)
document_id = response.json()["document_id"]
print(f"Document ID: {document_id}")

# 2. –ü–æ–∏—Å–∫ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç—É
response = requests.post(
    f"{BASE_URL}/langchain/query",
    json={
        "document_id": document_id,
        "query": "–ö–∞–∫–æ–≤—ã —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —É—á–∞—Å—Ç–Ω–∏–∫–∞–º?",
        "top_k": 5
    }
)
results = response.json()["results"]
for result in results:
    print(f"Score: {result['score']:.2f}")
    print(f"Text: {result['page_content'][:200]}...")
```

### –°—Ü–µ–Ω–∞—Ä–∏–π 2: –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ (—Ç—Ä–µ–±—É–µ—Ç—Å—è LLM API –∫–ª—é—á)

```python
import requests

BASE_URL = "http://localhost:8000"

# –°—É–º–º–∞—Ä–∏–∑–æ–≤–∞—Ç—å —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
response = requests.post(
    f"{BASE_URL}/langchain/summarize",
    json={
        "document_id": "550e8400-e29b-41d4-a716-446655440000",
        "strategy": "map_reduce",  # –∏–ª–∏ "stuff" / "refine"
        "max_chunks": 100
    }
)

result = response.json()
print(f"–†–µ–∑—é–º–µ ({result['chunks_processed']} —á–∞–Ω–∫–æ–≤):")
print(result['summary'])
```

**–°—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏:**
- `stuff` - –í—Å–µ —á–∞–Ω–∫–∏ –≤ –æ–¥–∏–Ω –ø—Ä–æ–º–ø—Ç (–±—ã—Å—Ç—Ä–æ, –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)
- `map_reduce` - –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –∫–∞–∂–¥–æ–≥–æ —á–∞–Ω–∫–∞, –∑–∞—Ç–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ (–ª—É—á—à–µ –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö)
- `refine` - –ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ —É—Ç–æ—á–Ω–µ–Ω–∏–µ (—Å–∞–º–æ–µ —Ç—â–∞—Ç–µ–ª—å–Ω–æ–µ, –º–µ–¥–ª–µ–Ω–Ω–µ–µ)

### –°—Ü–µ–Ω–∞—Ä–∏–π 3: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –ø—É–Ω–∫—Ç–æ–≤

```python
import requests

BASE_URL = "http://localhost:8000"

# –ò–∑–≤–ª–µ—á—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—É–Ω–∫—Ç—ã –ø–æ —Ç–µ–º–∞–º
response = requests.post(
    f"{BASE_URL}/langchain/extract_points",
    json={
        "document_id": "550e8400-e29b-41d4-a716-446655440000",
        "topics": [
            "–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —É—á–∞—Å—Ç–Ω–∏–∫–∞–º —Ç–µ–Ω–¥–µ—Ä–∞",
            "–°—Ä–æ–∫–∏ –ø–æ–¥–∞—á–∏ –∑–∞—è–≤–æ–∫",
            "–ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π"
        ],
        "chunks_per_topic": 3,
        "summarize": True  # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: —Å—É–º–º–∞—Ä–∏–∑–æ–≤–∞—Ç—å –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —á–∞–Ω–∫–∏
    }
)

result = response.json()
for point in result['extracted_points']:
    print(f"\nüìå –¢–µ–º–∞: {point['topic']}")
    print(f"–ù–∞–π–¥–µ–Ω–æ —á–∞–Ω–∫–æ–≤: {len(point['relevant_chunks'])}")
    if point['summary']:
        print(f"–†–µ–∑—é–º–µ: {point['summary']}")
```

**–ë–µ–∑ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏** (–Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è LLM API –∫–ª—é—á):
```python
response = requests.post(
    f"{BASE_URL}/langchain/extract_points",
    json={
        "document_id": document_id,
        "topics": ["–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —É—á–∞—Å—Ç–Ω–∏–∫–∞–º"],
        "chunks_per_topic": 5,
        "summarize": False  # –¢–æ–ª—å–∫–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ, –±–µ–∑ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
    }
)

# –ü–æ–ª—É—á–∏—Ç–µ raw relevant chunks
for point in result['extracted_points']:
    for chunk in point['relevant_chunks']:
        print(chunk)
```

## –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –º–µ–∂–¥—É —Å–∏—Å—Ç–µ–º–∞–º–∏

–î–æ–∫—É–º–µ–Ω—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ `/ingest` –º–æ–∂–Ω–æ —Å—É–º–º–∞—Ä–∏–∑–æ–≤–∞—Ç—å —á–µ—Ä–µ–∑ LangChain:

```python
# 1. –ó–∞–≥—Ä—É–∑–∏—Ç—å —á–µ—Ä–µ–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é —Å–∏—Å—Ç–µ–º—É
response = requests.post(
    f"{BASE_URL}/ingest",
    json={"document_name": "Doc", "text": "..."}
)
document_id = response.json()["document_id"]

# 2. –°—É–º–º–∞—Ä–∏–∑–æ–≤–∞—Ç—å —á–µ—Ä–µ–∑ LangChain
response = requests.post(
    f"{BASE_URL}/langchain/summarize",
    json={"document_id": document_id, "strategy": "map_reduce"}
)
print(response.json()["summary"])
```

–ò –Ω–∞–æ–±–æ—Ä–æ—Ç - –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ `/langchain/ingest` –º–æ–∂–Ω–æ –∏—Å–∫–∞—Ç—å —á–µ—Ä–µ–∑ `/query`.

## –°—Ç–æ–∏–º–æ—Å—Ç—å –∏ –ª–∏–º–∏—Ç—ã

### LLM API Costs

LangChain endpoints (`/langchain/summarize`, `/langchain/extract_points` —Å `summarize=true`) –∏—Å–ø–æ–ª—å–∑—É—é—Ç –≤–Ω–µ—à–Ω–∏–µ LLM API:

**OpenAI gpt-4o-mini** (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è):
- Input: $0.15 / 1M tokens
- Output: $0.60 / 1M tokens
- –ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ 50-—á–∞–Ω–∫–æ–≤–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞: $0.01-0.05

**OpenAI gpt-4o**:
- –î–æ—Ä–æ–∂–µ, –Ω–æ –±–æ–ª–µ–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–µ–∑—é–º–µ
- Input: $2.50 / 1M tokens

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

1. **–î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è**: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `gpt-4o-mini` —Å –Ω–µ–±–æ–ª—å—à–∏–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
2. **–î–ª—è production**:
   - –î–æ–±–∞–≤—å—Ç–µ rate limiting
   - –ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ OpenAI dashboard
   - –ö—ç—à–∏—Ä—É–π—Ç–µ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
3. **–î–ª—è —ç–∫–æ–Ω–æ–º–∏–∏**:
   - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `max_chunks` –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
   - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `extract_points` –≤–º–µ—Å—Ç–æ –ø–æ–ª–Ω–æ–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –≥–¥–µ –≤–æ–∑–º–æ–∂–Ω–æ

## Troubleshooting

### –û—à–∏–±–∫–∞: "LangChain functionality is disabled"

–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –≤ `.env`:
```env
LANGCHAIN_ENABLED=true
```

### –û—à–∏–±–∫–∞: "LLM API key is not configured"

–î–æ–±–∞–≤—å—Ç–µ –≤ `.env`:
```env
LLM_API_KEY=sk-your-openai-api-key
```

### –û—à–∏–±–∫–∞: "No chunks found for document_id"

–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —á—Ç–æ –¥–æ–∫—É–º–µ–Ω—Ç —Å—É—â–µ—Å—Ç–≤—É–µ—Ç:
```bash
curl http://localhost:8000/langchain/query \
  -H "Content-Type: application/json" \
  -d '{"document_id": "your-id", "query": "test", "top_k": 1}'
```

### –ú–µ–¥–ª–µ–Ω–Ω–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è

- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `strategy="stuff"` –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–±—ã—Å—Ç—Ä–µ–µ)
- –£–º–µ–Ω—å—à–∏—Ç–µ `max_chunks` –ø–∞—Ä–∞–º–µ—Ç—Ä
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ latency –¥–æ OpenAI API

## –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ü–æ–ª–Ω—ã–π workflow: –∑–∞–≥—Ä—É–∑–∫–∞ ‚Üí –ø–æ–∏—Å–∫ ‚Üí —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è ‚Üí –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ

```python
import requests

BASE_URL = "http://localhost:8000"

# 1. –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç
doc_response = requests.post(
    f"{BASE_URL}/langchain/ingest",
    json={
        "document_name": "–¢–µ–Ω–¥–µ—Ä–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è 2024",
        "text": open("tender_document.txt").read()
    }
)
doc_id = doc_response.json()["document_id"]
print(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç –∑–∞–≥—Ä—É–∂–µ–Ω: {doc_id}")

# 2. –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
query_response = requests.post(
    f"{BASE_URL}/langchain/query",
    json={"document_id": doc_id, "query": "—Å—Ä–æ–∫–∏", "top_k": 3}
)
print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(query_response.json()['results'])} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤")

# 3. –ü–æ–ª–Ω–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞
summary_response = requests.post(
    f"{BASE_URL}/langchain/summarize",
    json={"document_id": doc_id, "strategy": "map_reduce"}
)
print(f"‚úÖ –†–µ–∑—é–º–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞:")
print(summary_response.json()['summary'])

# 4. –ò–∑–≤–ª–µ—á—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—É–Ω–∫—Ç—ã
extract_response = requests.post(
    f"{BASE_URL}/langchain/extract_points",
    json={
        "document_id": doc_id,
        "topics": ["–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è", "–°—Ä–æ–∫–∏", "–ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏"],
        "summarize": True
    }
)
print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(extract_response.json()['extracted_points'])} –ø—É–Ω–∫—Ç–æ–≤")
```

## –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- **API Documentation**: `http://localhost:8000/docs`
- **LangChain Docs**: https://python.langchain.com/docs/
- **OpenAI Pricing**: https://openai.com/api/pricing/
- **CLAUDE.md**: –ü–æ–ª–Ω–∞—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
