# Qdrant settings
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=
COLLECTION_NAME=documents2

# Embedding models
# Legacy single model (for backward compatibility)
EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2

# Multiple models to load at startup (all kept in RAM)
EMBEDDING_MODELS=["sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2", "intfloat/multilingual-e5-base", "deepvk/USER-bge-m3"]

# Default model for /ingest and /query endpoints
DEFAULT_EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
DEFAULT_VECTOR_NAME=fast-paraphrase-multilingual-minilm-l12-v2

# Chunking strategy: paragraph или recursive
CHUNKING_STRATEGY=paragraph

# Настройки для recursive chunking
CHUNK_SIZE=500
CHUNK_OVERLAP=50

# API settings
API_HOST=0.0.0.0
API_PORT=8000

# LangChain integration settings
LANGCHAIN_ENABLED=true
LANGCHAIN_DEBUG=false  # Включить режим отладки (показывает все промпты, ответы LLM, промежуточные шаги)
LLM_PROVIDER=openai
LLM_API_KEY=
LLM_BASE_URL=http://127.0.0.1:9998/v1
# Примеры custom URL:
# LLM_BASE_URL=http://localhost:11434/v1  # для Ollama
# LLM_BASE_URL=http://localhost:8080/v1   # для LM Studio
# LLM_BASE_URL=https://api.your-provider.com/v1
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.0
